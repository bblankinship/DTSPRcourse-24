{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50650361",
   "metadata": {},
   "source": [
    "# Essential Data Structures in Python\n",
    "## Week 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fae6f0",
   "metadata": {},
   "source": [
    "This notebook has 4 sections, corresponding to the topics covered this week: \n",
    "1. List\n",
    "    - 1.1 List comprehension \n",
    "    - 1.2 Working with lists \n",
    "2. Array\n",
    "    - 2.1 Creating arrays \n",
    "    - 2.2 Reshaping arrays \n",
    "    - 2.3 Array Truthy and Falsy\n",
    "3. Dictionary\n",
    "    - 3.1 Dictionary comprehension \n",
    "4. Data frame\n",
    "    - 4.2 the Index \n",
    "    - 4.2 Working with data frames\n",
    "    - 4.3 Missing values in data frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d52c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by loading required packages and modules \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d13970",
   "metadata": {},
   "source": [
    "## 1. List \n",
    "\n",
    "We can create lists in Python using square brackets `[]`. Lists are heterogenous data structures, so they can include data elements of various data types, including lists themselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = [\"cat\", \"dog\", 45.3, \"horse\", \"fish\", 68]\n",
    "\n",
    "print(list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548427ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(list_a[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b71c5",
   "metadata": {},
   "source": [
    "As a built-in data structure, there are a lot of useful functions when working with lists. To see these type the name of the list object followed by a dot and hit the [TAB] key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## try it here - put your cursor after the . and hit [TAB]\n",
    "list_a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e81ca7",
   "metadata": {},
   "source": [
    "We can also request information about lists, such as the length using `len()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf3f72",
   "metadata": {},
   "source": [
    "### 1.1 **List comprehension** \n",
    "is an elegant way of creating lists, often with a single line of code. Compare the following two cells, both of which produce the same output - namely, a new list containing only fruits with the letter `\"a\"` in the name. \n",
    "\n",
    "List comprehension offers a streamlined syntax as follows: \n",
    "* `newlist = [expression for item in iterable if condition == True]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\n",
    "# create an empty list \n",
    "newlist = []\n",
    "\n",
    "# use a function to fill the empty list \n",
    "for x in fruits:\n",
    "    if \"a\" in x:\n",
    "        newlist.append(x)\n",
    "\n",
    "print(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c8fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## list comprehension solution \n",
    "\n",
    "newlist_comp = [x for x in fruits if \"a\" in x]\n",
    "\n",
    "print(newlist_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f8dd8",
   "metadata": {},
   "source": [
    "### 1.2 Working with lists \n",
    "\n",
    "To add an item to the end of a list, for example, we can use `listobject.append()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50402263",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a.append(\"antelope\")\n",
    "\n",
    "print(list_a) \n",
    "\n",
    "## run this code cell a few times and see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1fe92",
   "metadata": {},
   "source": [
    "To remove a specific item from a list we can use `listobject.remove()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a.remove(45.3)\n",
    "\n",
    "print(list_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ba70b",
   "metadata": {},
   "source": [
    "We can join two lists together in Python by simply using the `+` sign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26307e0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_a + fruits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c159b",
   "metadata": {},
   "source": [
    "You can sequentially iterate over a list using a for loop. In Python, we use a \"for in\" loop construction which is similiar to \"for each\" loops you find in C++ and Java. For Loop Syntax is as follows: \n",
    "\n",
    "` for iterator in sequence: \n",
    "     statements(s)`\n",
    "\n",
    "Note that white space indendtation, as mentioned in Week 1, is important here! If you go to a new line after the colon `:` (by pressing ENTER, Jupyter will automatically do this indentation for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281ed3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using a for loop to iterate over a list and print each element \n",
    "## using range(len(list)) to obtain the index of each element \n",
    "\n",
    "for i in range(len(list_a)):\n",
    "    print( list_a[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb65e4",
   "metadata": {},
   "source": [
    "As mentioned above lists can be comprised of more lists, this results in a list of lists being comprised of 2 dimensions. We can index such a list with `list[dim1][dim2]`. Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a two-dimensional list:\n",
    "list_of_lists = [[3,4,5,6,7], [30,40,50,60,70]] \n",
    "\n",
    "# print the big list\n",
    "print(list_of_lists) \n",
    "\n",
    "# print first sub-list\n",
    "print(list_of_lists[0]) \n",
    "\n",
    "# print first number in first sub-list\n",
    "print(list_of_lists[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2240d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remember indexes count from 0. So first element has index 0, second index 1, third index 2, etc\n",
    "# to go into the second list, then to its fourth element (which should have value 60), you would use\n",
    "print(list_of_lists[1][3])\n",
    "\n",
    "# negative numbers count from the end\n",
    "# to get from the first list its last element (which should be 7), you would use\n",
    "print(list_of_lists[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd22eb",
   "metadata": {},
   "source": [
    "In most instances, your data will have many dimensions. As a recap: \n",
    "    \n",
    "- a variable has **zero dimensions** - you do not need any more index/address to know what's in it\n",
    "- a list/array has **one dimension** - index is the way to address individual items in a list\n",
    "- a list of lists has **two dimensions** - index of the top list, and then an index of the inner list  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92ff30",
   "metadata": {},
   "source": [
    "## 2. Array \n",
    "\n",
    "Array is is basically like a List, but has a number of new very powerful methods and syntax that make data operations easier and faster. Theoretically you could do everything that we do with Arrays by just using good old Lists, but it would take more time and be less compatible with other libraries.\n",
    "\n",
    "To create an Array, you can cast a list into `np.array(your_list)`. Notice the `np.array` at the begining - it means that you are using the `array class` from the ```np``` library. `np` is a short name for `numpy` (which we gave it in `import numpy as np` at the top of this notebook)\n",
    "\n",
    "To work with array data structures, we need to `NumPy` package. In fact, `NumPy` was designed specifically to perform numerical operations with n-dimensional arrays. Arrays store values of the same data type. The NumPy vectorization of arrays significantly enhances performance and accelerates the speed of computing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93699d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [3, 7, 5, 5]\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can create an array by feeding in a List directly or as a data object:\n",
    "\n",
    "my_array = np.array(my_list)\n",
    "print(my_array)\n",
    "\n",
    "my_array2 = np.array([3, 0, 5, 0])\n",
    "print(my_array2)\n",
    "\n",
    "# notice it is printed a bit differently than a list! \n",
    "# the commas are not present compared to the list print out in the cell above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fbb52",
   "metadata": {},
   "source": [
    "Arrays are often used in situations where there are many dimensions. So a grid of \n",
    "\n",
    "`\n",
    "1,  2,  3,  4\n",
    "11, 12, 13, 14\n",
    "21, 22, 23, 24\n",
    "`\n",
    "\n",
    "Can be represented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82854d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([ [1, 2, 3, 4],\n",
    "                    [11, 12, 13, 14],\n",
    "                    [21, 22, 23, 24]\n",
    "                   ])\n",
    "# do you see it? A list with 3 lists, each with 4 items inside!\n",
    "\n",
    "print(scores)\n",
    "\n",
    "# let's print what type of a thing it is:\n",
    "print(type(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913aecde",
   "metadata": {},
   "source": [
    "`Numpy` arrays bring with them a new addressing style. We can use `array[first_dimension, second_dimension, third_dimension, ....]`, meaning you can pass an index of each next dimension separated by commas. You can use the same style (pure Python way) as with lists we looked at above ```my_list[first_dimention][second_dimention]```, but using a single square brackets with commas for dimensions is more common. Let's see how this works with some multidimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea02b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## above we created a multidimensional array called scores \n",
    "\n",
    "print(scores[0, 0])\n",
    "print(scores[0, 1])\n",
    "print(scores[1, 2])\n",
    "print(scores[1, -1])\n",
    "print(scores[-1, -1])\n",
    "\n",
    "# look at the printed output and see if you understand why these numbers are printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe92cd",
   "metadata": {},
   "source": [
    "We can use the index to not only get a value, but also change it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f88598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's change some items\n",
    "\n",
    "# reassign values \n",
    "scores[0,0] = 10\n",
    "scores[0,1] = 20\n",
    "\n",
    "# change values mathamatically \n",
    "scores[1,3] += 30\n",
    "scores[-1,-1] += 40\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e7a99",
   "metadata": {},
   "source": [
    "You can also ommit one of the dimensions, and replace everything in a row or column. Use colon `:` to indicate 'everything'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([ [1,  2,   3,  4],\n",
    "                    [11, 12, 13, 14],\n",
    "                    [21, 22, 23, 24]\n",
    "                   ])\n",
    " \n",
    "scores[0,:] = 10 \n",
    "print(scores)\n",
    "# first dimention: value 0, second dimention: all values\n",
    "# note you could also use simpler version scores[0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef790159",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = np.array([ [1,  2,   3,  4],\n",
    "                    [11, 12, 13, 14],\n",
    "                    [21, 22, 23, 24]\n",
    "                   ])\n",
    " \n",
    "scores[:,2] = 30  \n",
    "print(scores)\n",
    "# first dimention: all values, second dimention: value 2\n",
    "# note but here you cannot simplify it to scores[,2] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef67c3",
   "metadata": {},
   "source": [
    "To slice arrays there is a new syntax, which can be used in lists and data frames as well! ` my_array[start_index : stop_index : step/jump]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = np.arange(10,20)\n",
    "print(digits)\n",
    "print(digits[2:7:2]) # from index 2, till index 7, jumping every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee06c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits[:7:2]) # from beginning, till index 7, jumping every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits[2::2]) # from index 2, till end, jumping every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850385dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits[::2]) # all, jumping every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9746a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with negative step/jump the array gets reversed\n",
    "print(digits[::-1]) # all, but index counting down\n",
    "print(digits[::-3]) # all, but index counting down every 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c9d0a",
   "metadata": {},
   "source": [
    "There is a variety of information you can request about arrays with methods including: \n",
    "* dimension with `.ndim`\n",
    "* shape with `.shape`\n",
    "* size with `.size`\n",
    "* data type with `.dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0ffab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# you can request some info about a multi-dimensional Arrays:\n",
    "scores = np.array([ [1, 2, 3, 4],\n",
    "                    [11, 12, 13, 14],\n",
    "                    [21, 22, 23, 24]\n",
    "                   ])\n",
    "\n",
    "print(\"dimensions:\", scores.ndim)\n",
    "print(\"shape:\", scores.shape)\n",
    "print(\"size:\", scores.size)\n",
    "print(\"data type:\", scores.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc91fa",
   "metadata": {},
   "source": [
    "### Creating arrays \n",
    "\n",
    "You can specify the default value and type of your new empty array:\n",
    "\n",
    "- full of zeros with `np.zeros()`\n",
    "- full of ones with `np.ones()`\n",
    "- full of some other value with `np.full(some_value)`\n",
    "- full of random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1700a747",
   "metadata": {},
   "source": [
    "As you can see, by default the values created are floats. But you can specify the data type with the `dtype` argument. It is good practice when creating arrays with specified values to be explicitly cast with the desired data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5, dtype = 'bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb11d5",
   "metadata": {},
   "source": [
    "You can also create multi-dimentional arrays with sizes of all dimentions in a tuple (which we will learn more about next week - essentially it is a immuntable list made with `()`):\n",
    "\n",
    "- `(10)` - array of 10 elements\n",
    "- `(5,10)` - 5 sets of 10 elements\n",
    "- `(3,5,10)` - 3 sets of 5 sets of 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((10), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ea588",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((5,10), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8092cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.zeros((3, 5,10), dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d6094",
   "metadata": {},
   "source": [
    "You can also specify values other than zero with `np.ones( dimensions )` or with `np.full(dimensions, value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbeb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((2,5), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22456b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.full((2,5), 3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b785aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# so as you can these two do the same thing:\n",
    "\n",
    "print(np.ones((2,5), dtype = int))\n",
    "print(np.full((2,5), 1))\n",
    "\n",
    "# in programming there are often multiple ways of doing the same thing! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b35cbf",
   "metadata": {},
   "source": [
    "You can also create values\n",
    "\n",
    "- from a range with `np.arange(start, top, jump)`\n",
    "- with even split between two values `np.linspace(start, end, slices)`\n",
    "- indentity matrix with `eye(size)`\n",
    "- to repeat a pattern with `np.tile()`\n",
    "- full of random data with `np.random.randint(max_value, size = (size_tuple))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(5, 50, 10) # range has start, end, jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a361b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 5) # from_value, to_value, how_many_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 100, 3, dtype = int) # from_value, to_value, how_many_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ad6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = np.array([0, 1, 2])\n",
    "\n",
    "np.tile(pattern, 2) # the number (or tuple) given in tile describes size/times of output matrix # repeat 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(pattern, (3,2))\n",
    "# repeat 2 times in one dimension, and 3 times in another dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random numbers\n",
    "print(np.random.randint(10, size = 6))\n",
    "\n",
    "# every time you run this cell, your random numbers will be differnt. \n",
    "## Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ab287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but if you specify a seed, your random numbers will be the same every time you run this cell! \n",
    "# this can be very helpful when debugging or in some statitical analyses using random numbers or sampling \n",
    "\n",
    "np.random.seed(0) # plant the seed 0 - this could be any number\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "\n",
    "## run this cell a few times to see that the numbers do not change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0953d3",
   "metadata": {},
   "source": [
    "Let's now create some arrays full of random values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b687e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE DIMENTION - with size 6\n",
    "array1 = np.random.randint(100, size = 6)\n",
    "print(array1)\n",
    "print(array1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf15a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO DIMENTIONS - with size 4 for first and 5 for the second\n",
    "# these could be scores for four courses, each with 5 students\n",
    "\n",
    "array2 = np.random.randint(100, size = (4, 5))\n",
    "print(array2)\n",
    "print() # empty print statement to organise output a bit easier \n",
    "\n",
    "print(array2[3])\n",
    "print()\n",
    "print(array2[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484164f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THREE DIMENTIONS - with size 3 for first and 4 for the second and 5 for third\n",
    "array3 = np.random.randint(100, size = (3, 4, 5))\n",
    "\n",
    "print(array3)\n",
    "\n",
    "# change the numbers in size to ensure you are understanding what they are doing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e402ac",
   "metadata": {},
   "source": [
    "### 2.2 Reshaping arrays \n",
    "\n",
    "We can change the dimensions of an array with `.reshape()` We can concatinate or flatten arrays(and lists!) using `np.concatenate()` which will remove 1 dimension. We can also split one array into many arrays unsing predefined indexes with the `np.split()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37247b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets start out with a one dimensional array \n",
    "print(np.arange(12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(12).reshape((2, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76592f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(12).reshape((4, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9984e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(12).reshape((3, 2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80d43f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This causes an erorr - you can't split 12 numbers into 4 sets of 5 numbers!\n",
    "print(np.arange(12).reshape((4, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49784fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arraya = np.array([10,20,30])\n",
    "arrayb = np.array([40,50,60])\n",
    "parent_array = [arraya, arrayb]\n",
    "\n",
    "print(parent_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3798a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.concatenate(parent_array) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416687ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## works the same for 2-D lists \n",
    "lista = [70, 80,90]\n",
    "listb = [1, 2, 3]\n",
    "\n",
    "print( np.concatenate([lista, listb]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can even concatenate lists and arrays together. They really are very simmilar\n",
    "arraya = np.array([10,20,30])\n",
    "arrayb = np.array([40,50,60])\n",
    "lista = [70, 80,90]\n",
    "\n",
    "print( np.concatenate([arraya, arrayb, lista]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation respects dimensions, it will flatten only the top dimension\n",
    "two_dimension_array1 = np.array([ [1,2,3],    [4,5,6] ])\n",
    "two_dimension_array2 = np.array([ [10,20,30], [40,50,60] ])\n",
    "\n",
    "print(two_dimension_array1)\n",
    "print()\n",
    "print(two_dimension_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.concatenate([two_dimension_array1,two_dimension_array2]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766b377",
   "metadata": {},
   "source": [
    "Concatenate has an extra argument called `axis`: ```np.concatenate([arr1, arr2], axis = 0)``` which by default is 0\n",
    "\n",
    "- `axis = 0` (the default) - flatten horizontally - remove one dimension from all items in list\n",
    "- `axis = 1` - flatter vertically - combine all first items, then all second items, all third... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d659d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimension_array1 = np.array([ [1,2,3], [4,5,6] ])\n",
    "two_dimension_array2 = np.array([ [10,20,30], [40,50,60] ])\n",
    "\n",
    "print( np.concatenate([two_dimension_array1,two_dimension_array2], axis = 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ece294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( np.concatenate([two_dimension_array1, two_dimension_array2], axis = 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = np.arange(1, 10)\n",
    "print(digits)\n",
    "\n",
    "three_sub_arrays = np.split(digits, [3, 6])\n",
    "print(three_sub_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c7dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have not seen this syntax yet, it's typical used in more advanced uses of Python. \n",
    "# You can specify many variables in one line, but assigning a List to them - see how useful data structures can be! \n",
    "\n",
    "a, b, c = [10,20,30]\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so split can be used as follows: \n",
    "\n",
    "start, middle, end = np.split(digits, [3, 6])\n",
    "print(start, middle, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you could achieve the same effect with many lines of code with range()\n",
    "# but that requires much more thinking and opportunities for mistakes \n",
    "\n",
    "first = np.arange(1, 4)\n",
    "second = np.arange(4, 7)\n",
    "third = np.arange(7, 10)\n",
    "print(first, second, third)\n",
    "\n",
    "# but why do something the hard way if there is a proper syntax for it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b543475",
   "metadata": {},
   "source": [
    "### 2.3 Array Truthy and Falsy\n",
    "Like numbers which we learned about in week 2 and 3, arrays evaluate as truthy and falsy depending on how they compare to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([0])\n",
    "\n",
    "print(a1)\n",
    "\n",
    "print(len(a1))\n",
    "\n",
    "print(bool(a1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5ee85",
   "metadata": {},
   "source": [
    "Even though `a1` has a length of 1, it is still falsy because its value is 0. When arrays have more than one element, some elements might be falsy and some might be truthy. In those cases, NumPy will raise a `ValueError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c101349",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.array([0, 1])\n",
    "\n",
    "bool(a2) #produces a value error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## are any values truthy\n",
    "print(a2.any())\n",
    "\n",
    "## are all values truthy\n",
    "print(a2.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70ffc2",
   "metadata": {},
   "source": [
    "## 3. Dictionary \n",
    "\n",
    "As a reminder, we create dict data structures in Python using curly brackets `{}` and specifying the `key:value` pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"city\" : \"Edinburgh\",\n",
    "       \"univeristy\" : \"UoE\",\n",
    "       \"year\" : 1583}\n",
    "\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fc62f",
   "metadata": {},
   "source": [
    "As a built-in data structure, list lists, there are a lot of useful functions when working with dictionaries. To see these type the name of the dictionary object followed by a dot and hit the [TAB] key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54efe3d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## try this here - put your cursor after the . and hit [TAB]\n",
    "dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcec15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to see the list of keys \n",
    "print(dict.keys())\n",
    "\n",
    "#to see the list of values \n",
    "print(dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af54b90",
   "metadata": {},
   "source": [
    "You can also access each key-value pair within a dictionary using the `.items()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cec7d5",
   "metadata": {},
   "source": [
    "Since we cannot have duplicate keys, you can change the `key:value` mapping by setting the key to a new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict[\"city\"] = \"Glasgow\"\n",
    "\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d6c43",
   "metadata": {},
   "source": [
    "Using the same syntax though with a unique key, you can add a new item to a dict data structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93acf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict[\"campus\"] = \"George square\"\n",
    "\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34204b",
   "metadata": {},
   "source": [
    "### 3.1 Dictionary comprehension \n",
    "\n",
    "Dictionary comprehension has been available since Python 2.7 and like list comprehension, is an efficient way of creating new dictionaries. Dictionary comprehensions takes the form: `{key: value for (key, value) in iterable}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a307fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_comp = {x: x**2 for x in [1,2,3,4,5]} \n",
    "\n",
    "print(dict_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4a761",
   "metadata": {},
   "source": [
    "Let's say that now we want to double each value in our dictionary that we created called `dict_comp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7efe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_double = {k:v*2 for (k,v) in dict_comp.items()}\n",
    "\n",
    "print(dict_double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306bf2a3",
   "metadata": {},
   "source": [
    "You can also use dictionary comprehension to make changes to the key values. Let's make the same dictionary as `dict_double` but also change the names of the key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd23c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys = {k*10:v for (k,v) in dict_double.items()}\n",
    "\n",
    "print(dict_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb99527",
   "metadata": {},
   "source": [
    "A useful function of Python dictionaries is to convert them to data frames. When a dictionary is converted to dataframe, the key become the column name and the value becomes the elements of the series (in other words the rows of a column). The function we use for this is `pd.DataFrame.from_dict()`. Use `orient='index'` to create the DataFrame using dictionary keys as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict, orient = \"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da153fa",
   "metadata": {},
   "source": [
    "## 4. Data frames\n",
    "\n",
    "A data frame is a 2 dimensional structure (rows and columns) which can contain hetereogenous data typed elements. Data frames are not a built-in Python data struture, thus we need to `pandas` package in order to access and work with this data structure.\n",
    "\n",
    "We will be using the gapminder data set, which is available in R in the `gapminder` package. We saw this dataset briefly in the Week 1 tutorial. Lets read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13466de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_data = pd.read_csv(\"../data/gapminder_data_unfiltered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e55696",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check data descriptions \n",
    "\n",
    "print(gap_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all columns not just numeric data - by default the describe method includes only numeric data  \n",
    "print(gap_data.describe(include = \"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check df dtype of data frame columns\n",
    "gap_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bf440",
   "metadata": {},
   "source": [
    "To slice or subset rows, we can use the same notation as with arrays `dataframe[start: stop: step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d19464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gap_data[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fa4aa",
   "metadata": {},
   "source": [
    "To access columns, we can use `[]` with the column name or a dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6cae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a column with [] \n",
    "# Notice meta information about names and data types at the bottom!\n",
    "print(gap_data['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0037f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# but quite frequently you would use a . dot notation, like this:\n",
    "print(gap_data.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942832d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to get individual items\n",
    "print(gap_data.year[0])\n",
    "\n",
    "# same as - just a different style of syntax \n",
    "print(gap_data['year'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or a few individual items\n",
    "print(gap_data.year[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d146f",
   "metadata": {},
   "source": [
    "### 4.1 the Index \n",
    "\n",
    "The index is the most important part of your data. It should be unique, but does not have to be. \n",
    "\n",
    "If you do not specify the index in your data, Python will just use continuous numbers starting from 0 (like 0,1,2,3,4,...). It's sort of like a row name in Excel.\n",
    "\n",
    "```.set_index(a_column_name)``` will set a column with name `a_column_name` to be the index\n",
    "\n",
    "```drop=False``` will make the old column stay (it will sort-of get duplicated and you'd have two identical columns: the original one, and the new index column)\n",
    "\n",
    "You could also have many columns act as  indexes, but we will not go into that. If you wanted to do that, just pass a List of column names to `set_index` rather than one column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e04e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the index is the numbers on the left (0-3308)\n",
    "# notice it does not have a column/variable name \n",
    "gap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27639c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we can turn 1 of the columns into the index \n",
    "# notice the spacing difference between the column names and the index name \n",
    "gap_data.set_index(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17a46a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# but notice above year is now gone. to keep that column as it was, add drop = False\n",
    "gap_data_yindex = gap_data.set_index(\"year\", drop = False)\n",
    "gap_data_yindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now you can use your index to get whole rows from the dataframe\n",
    "# this can be bit cleaner than indexes 1,2,3,4... depending on your data\n",
    "gap_data_yindex.loc[[1987]]\n",
    "\n",
    "## see section below for what the .loc method does "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7232a",
   "metadata": {},
   "source": [
    "## 4.2 Working with data frames \n",
    "\n",
    "When working with data frames, there are a wide variety of functionalities available to you through `pandas`. Here we will focus on some key functions and attributes: \n",
    "\n",
    "* `groupby()` to perform subgroup analysis on your data\n",
    "* `reset_index()` to reset the index of your data frame. It is good practice to do this after `groupby()` in particular to avoid funky and unexpected results\n",
    "* `assign()` to assign or calculate a new column. `assign()` *does not* change the original dataframe, which is a special change of pace! That's because if you specified `inplace=True` it would just add a column called 'inplace' and put values True in every row of that column. \n",
    "* `agg()` aggregate using one or more operations over a specified range of columns or rows \n",
    "* `isin()` along side slicing to filter specific rows of a data frame\n",
    "* `query()` to query or filter columns of a data frame with a boolean expression \n",
    "* `loc` to select rows and columns by labels or a boolean array, stands for location\n",
    "* `iloc` to select rows and columns by integer-location indexing for selecting by position, stands for integer-location\n",
    "* `df.astype()` to change the data type of a `pandas` object\n",
    "\n",
    "You can also assign new values to a selection of your data frame using `loc`/`iloc`.\n",
    "\n",
    "When combining multiple conditional statements, each condition must be surrounded by parentheses `()`. Additioanlly, in `pandas` you *cannot* use `or`/`and` but need to use the 'or' operator `|` and the 'and' operator `&`.\n",
    "\n",
    "`pandas` data frame provide a full set of all statistical methods as well. If you need something specific, always [look in the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60129a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mean of all populations in the dataset grouped by continent \n",
    "\n",
    "print(gap_data[\"pop\"].groupby(gap_data[\"continent\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0970905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data to be only year and continent variables\n",
    "\n",
    "gap_filter = gap_data.iloc[:, 0:2].copy()\n",
    "\n",
    "## [:, 0:2] reads as everything or all rows, slicing columns to be only the first 2 following [row, columns]\n",
    "## .copy() method to get a regular copy, to avoid the case where changing gap_filter also changes gap_data\n",
    "\n",
    "gap_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd471b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to be only 1980 and before\n",
    "\n",
    "gap_data.loc[gap_data[\"year\"] >= 1980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abe626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to be specific countries\n",
    "\n",
    "gap_data.loc[gap_data[\"country\"].isin([\"Thailand\", \"Peru\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean of a column \n",
    "\n",
    "print(gap_data[\"gdpPercap\"].mean())\n",
    "\n",
    "## or you could use \n",
    "print(gap_data.gdpPercap.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f413796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new variable called mean_gdpPercap with the mean of the whole data set using assign \n",
    "\n",
    "gap_data.assign(mean_gdpPercap = gap_data[\"gdpPercap\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8acb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try again and see how inplace does something unexpected, as mentioned above \n",
    "\n",
    "gap_data.assign(mean_gdpPercap = gap_data[\"gdpPercap\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the mean population across all years per country we just first need to do a groupby to group the data by country \n",
    "\n",
    "gap_data[\"pop\"].groupby(gap_data[\"country\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc5c72",
   "metadata": {},
   "source": [
    "We can use our knowledge of the dictionary data stucture to get a summary table of our data with aggregate statistics per column of interest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5dfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get a summary table with aggregations per column \n",
    "\n",
    "gap_data.agg({'year' : ['min', 'max'], 'pop' : ['sum', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083738c",
   "metadata": {},
   "source": [
    "We cast specific columns in a data frame to another dtype using `as.type()` and a dictionary. Lets make `year` a category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a899551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gap_data.astype({\"year\": \"category\"}).dtypes\n",
    "\n",
    "# adding .dtypes at the end has Python print out the dtype of the data frame after changing the year dtype \n",
    "## in this way we can check our work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbb12b",
   "metadata": {},
   "source": [
    "### 4.3 Missing values in data frames\n",
    "\n",
    "`pandas` treat `None` and `NaN` as essentially interchangeable for indicating missing or null values. To facilitate this convention, there are several useful functions for detecting, removing, and replacing null values in a `pandas` DataFrame:\n",
    "\n",
    "* `isnull()` returns a data frame of Boolean vlaues which are `True` for NaN values \n",
    "* `notnull()` returns a data frame of Boolean vlaues which are `False` for NaN values \n",
    "* `df.dropna()` allows you to analyze and drop Rows/Columns with missing values in different ways. By default uses row-wise deletion so all rows with missing data are deleted\n",
    "* `df.fillna()` allows you to replace missing values with some other specified value \n",
    "* `df.replace()` replaces a string, regex, list, dictionary, series, number, etc. from a `pandas` data frame\n",
    "* `df.interpolate()` which uses various interpolation technique to fill the missing values rather than hard-coding the value. This is particularly useful with numeric data although there are numerous methods available - [see the documentation if you are interested in learning more](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html)\n",
    "\n",
    "We looked at dealing with missing data in Week 2 & 3, but lets create a data frame with some missing data to remind ourselves how this works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a85d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to create a DataFrame we put a Dict it its constructor. But remember that values need to be lists\n",
    "patients = pd.DataFrame(\n",
    "    {\"names\": [\"Angela\", \"Shondra\", np.nan, \"Ben\"],\n",
    "     \"age\": [27, np.nan, 57, 44],\n",
    "     \"result\": [True, False, np.nan, False]})\n",
    "\n",
    "patients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae08d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check for missing values in a specific column\n",
    "patients.names.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb4e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd94e29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patients.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the method argument in fillna the fill missing data with previous item \n",
    "patients.fillna(method = \"ffill\") ## ffill being forward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14e559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# or to fill the missing data with the next viable observation \n",
    "patients.fillna(method = \"bfill\") # bfill meaning back fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae328d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the default method is linear which applies only to numeric data\n",
    "patients.interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c48b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.interpolate(method = \"pad\") # this method is the same as ffill "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc08d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## You did it! 🎉 \n",
    "\n",
    "Well done for making it to the end of this notebook. If you have not done so yet, move to the Week 4 data structures in R RMarkdown notebook next. \n",
    "\n",
    "⭐⭐⭐❓👣 Do not forget your 3 stars, a wish, and a step mini-diaries once you have completed the content for this week. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071973eb",
   "metadata": {},
   "source": [
    "---\n",
    "*Dr. Brittany Blankinship (2024)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
